<script src="http://www.google.com/jsapi" type="text/javascript"></script> 
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<html>
<head>
    <title>Sound Localization by Self-Supervised Time-Delay Estimation</title>
    <!-- <meta property="og:image" content=images/teaser.png"/> Facebook automatically scrapes this. Go to https://developers.facebook.com/tools/debug/ if you update and want to force Facebook to rescrape. -->
    <meta property="og:title" content="Sound Localization by Self-Supervised Time-Delay Estimation" />
    <meta property="og:description" content="Z. Chen, D. F. Fouhey, A. Owens." />
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- webpage template-->
    <link rel="stylesheet" href="assets/css/style.css">
    <!-- model-viewer css -->
    <link rel="stylesheet" href="assets/css/demo-style.css">

</head>

<body>
    <br>
    <!-- <center> -->
    <center>
        <span style="font-size:38px">Sound Localization by Self-Supervised Time-Delay Estimation</span>
    </center>
    <br><br>
    <table align=center width=60%>
        <tr>
            <td align=center width=33%>
                <center>
                    <span style="font-size:20px"><a href="https://ificl.github.io/">Ziyang Chen</a></span>
                </center>
            </td>
            <td align=center width=33%>
                <center>
                    <span style="font-size:20px"><a href="https://web.eecs.umich.edu/~fouhey/">David F. Fouhey </a></span>
                </center>
            </td>
            <td align=center width=33%>
                <center>
                    <span style="font-size:20px"><a href="http://andrewowens.com/">Andrew Owens</a></span>
                </center>
            </td>
        </tr>
    </table>
    <br>
    <table align=center width=60%>
        <tr>
            <td align=center width=100%>
                <center>
                    <span style="font-size:20px">University of Michigan</span>
                </center>
            </td>
        </tr>
    </table>
    <br>
    <!-- <table align=center width=60%>
        <tr>
            <td align=center width=100%>
                <center>
                    <span style="font-size:20px">CoRL 2021 (<span style="color:#a00"><b>Oral</b></span>)</span>
                </center>
            </td>
        </tr>
    </table> -->
    <br>
    <table align=center width=100%>
        <tr>
            <td align=center width=25%>
                <center>
                    <!-- <span style="font-size:20px"><a href="https://openreview.net/forum?id=ht3aHpc1hUt">[OpenReview]</a></span> -->
                </center>
            </td>
            <td align=center width=25%>
                <center>
                    <span style="font-size:20px"><a href="#">[Paper]</a></span>
                </center>
            </td>
            <td align=center width=25%>
                <center>
                    <span style="font-size:20px"><a href="https://github.com/IFICL/self-supervised-itd-estimation">[Github]</a></span>
                </center>
            </td>
            <td align=center width=25%>
                <center>
                    <!-- <span style="font-size:20px"><a href="">[Talk]</a></span> -->
                </center>
            </td>
            <!-- <td align=center width=20%>
                <center>
                    <span style="font-size:20px"><a
                            href="">[Slides]</a></span>
                </center>
            </td> -->
        </tr>
    </table>

    <br>

    <table align=center width=80%>
        <tr>
            <td width=100%>
                <center>
                    <img src="images/teaser.png" width="100%"></img><br>
                </center>
            </td>
        </tr>
        <tr>
        <td width=95%>
            <center>
                <span style="font-size:14px"><i> We learn from unlabeled audio (or audio-visual) data to estimate a sound's <b>interaural time delay</b>, the difference in the arrival time of a sound between two microphones. We show time-delay predictions for two scenes, along with their corresponding video frames (not used by the model). In both cases, the sound source changes its position in a scene, resulting in a corresponding change in time delay.</i> 
            </center>
        </td>
        </tr>
    </table>
    <br>
    <hr>

    <table align=center width=80%>
        <center><h1>Abstract</h1></center>
        <tr>
            <td>
                In stereo sound recordings, sounds arrive at one microphone slightly sooner than the other, resulting in an <b>interaural time delay</b> that conveys the direction of the sound. Estimating this delay requires finding correspondences between sounds in the two audio channels. We propose to learn these correspondences through self-supervision. We present methods, based on contrastive learning and cycle consistency, that successfully estimate time delays from unlabeled data and which obtain performance on par with state-of-the-art supervised methods on "in the wild" recordings. Our models easily integrate visual information and enable a novel <b>visually-guided</b> localization task: estimating the time delay for a particular speaker in a multi-speaker mixture, given a visual representation of their face.
            </td>
        </tr>
    </table>
    <br><br>
    <hr>

    <table align=center width=80%>
        <center>
            <h1>Dataset</h1>
        </center>
        <div align=center width=100%>
            <p  style="text-align: left; width: 80%" >
                <b>In-the-wild Evaluation Dataset</b> &nbsp &nbsp &nbsp We collected 30 internet binaural videos, extracted 1K samples from them,
                and use human judgements to label sound directions. These videos contain a variety of sounds, including engine noise and
                human speech. Dataset could be download from our <a href="https://github.com/IFICL/stereocrw">github repo</a>. We show some qualitative results from our model in the right-side video. Our method can predict more than left vs. right, we just do that to simplify evaluation.
            </p>
        </div>
        <tr>
            <td width=100%>
                <div>
                <p align="center">
                    <img src="images/dataset.png" width="100%"></img>
                </p>
                </div>
            </td>
        </tr>
        
    </table>
    <br>
    <hr>

    <!-- <table align=center width=100%>
        <center>
            <h1>Talk</h1>
        </center>
        <div>
            <p align="center">
            <iframe style="width: 70%; height: 60%; min-width:300px" src="https://www.youtube.com/embed/vpcTohC8OOg" frameborder="0"
                allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            </p>
        </div>
    </table>
    <br><br>
    <hr> -->

    <table align=center width=90%>
        <center>
            <h1>Qualitative Results</h1>
        </center>
        <tr>
            <td width=50%>
                <center>
                    <h3> In-the-wild video results </h3>
                </center>
            </td>
            <td width=50%>
                <center>
                    <h3> Visually-guided time delay estimation </h3>
                </center>
            </td>
        </tr>
        <tr>
            <td width=50%>
                <div>
                    <p align="center">
                        <iframe style="width: 100%; height: 100%; min-height:350px"  src="https://www.youtube.com/embed/Pu_on-VSRsE" title="YouTube video player"
                            frameborder="0"
                            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                            allowfullscreen></iframe>
                    </p>
                </div>
            </td>
            <td width=50%>
                <div>
                    <p align="center">

                    <iframe style="width: 100%; height: 100%; min-height:350px" src="https://www.youtube.com/embed/ngWIIpuZoKY" title="YouTube video player"
                        frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                        allowfullscreen></iframe>
                    </p>
                </div>
            </td>
        </tr>

        <tr>
            <td width=50%>
                <center>
                    <br></br>
                    <h3> Binaural car demo </h3>
                </center>
            </td>
            <td width=50%>
                <center>
                    <br></br>
                    <h3> iPhone video demo </h3>
                </center>
            </td>
        </tr>
        <tr>
            <td width=50%>
                <div>
                    <p align="center">
                        <iframe style="width: 100%; height: 100%; min-height:350px"
                            src="https://www.youtube.com/embed/LEDMk2whwSI" title="YouTube video player" frameborder="0"
                            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                            allowfullscreen></iframe>
                    </p>
                </div>
            </td>
            <td width=50%>
                <div>
                    <p align="center">
                        <!-- <iframe width="1140" height="641" src="" title="YouTube video player"
                                    frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                                    allowfullscreen></iframe> -->
                        <iframe style="width: 100%; height: 100%; min-height:350px"
                            src="https://www.youtube.com/embed/V5Qo17y8xCE" title="YouTube video player" frameborder="0"
                            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                            allowfullscreen></iframe>
                    </p>
                </div>
            </td>
        </tr>
    </table>
    <br><br>
    <hr>

    <table align=center width=60%>
        <center><h1>Paper and Supplementary Material</h1></center>
        <tr>
            <td><a href=""><img class="layered-paper-big" style="height:175px" src="./images/paper.png"/></a></td>
            <td><span style="font-size:14pt">Ziyang Chen, David F. Fouhey, Andrew Owens.<br>
                <b>Sound Localization by Self-Supervised Time-Delay Estimation.</b><br>
                arXiv 2022.<br>
                <!-- (hosted on <a href="#">ArXiv</a>)<br> -->
                (<a href="#">Arxiv</a>)<br>
                <span style="font-size:4pt"><a href=""><br></a>
                </span>
            </td>
        </tr>
    </table>
    <br>

    <table align=center width=60%>
        <tr>
            <td><span style="font-size:14pt"><center>
                <a href="./docs/bibtex.txt">[Bibtex]</a>
            </center></td>
        </tr>
    </table>

    <hr>
    <br>

    <table align=center width=80%>
        <tr>
            <td width=80%>
                <left>
                    <center><h1>Acknowledgements</h1></center>
                    This work was funded in part by DARPA Semafor and Cisco Systems. The views, opinions and/or
                    findings expressed are those of the authors and should not be interpreted as representing the official views or policies
                    of the Department of Defense or the U.S. Government. The webpage template was originally made by <a href="http://web.mit.edu/phillipi/">Phillip Isola</a> and <a href="http://richzhang.github.io/">Richard Zhang</a> for a <a href="http://richzhang.github.io/colorization/">Colorization</a> project. 
                </left>
            </td>
        </tr>
    </table>

<br>
</body>
</html>

